{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:36:27.470473Z","iopub.status.busy":"2023-04-08T20:36:27.469501Z","iopub.status.idle":"2023-04-08T20:39:03.678595Z","shell.execute_reply":"2023-04-08T20:39:03.674101Z","shell.execute_reply.started":"2023-04-08T20:36:27.470418Z"},"id":"55390e37","outputId":"c9c8815d-251f-4330-8a52-1d5beb2986ae","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-04-08 20:36:28--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 142.251.8.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3816687935 (3.6G) [application/zip]\n","Saving to: ‘nature_12K.zip’\n","\n","nature_12K.zip      100%[===================>]   3.55G  28.8MB/s    in 2m 5s   \n","\n","2023-04-08 20:38:34 (29.1 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n","\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from math import ceil as ceil\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","import wandb\n","!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n","!unzip -q /kaggle/working/nature_12K.zip"]},{"cell_type":"markdown","metadata":{},"source":["The Following class prepData prepares the data with the option to augment or not\n","- it returns training data Loader, validation Data Loader, test Data Loader and the class Names dictionary\n","\n","- it takes a boolean(augment) as it's input which decides whether to augment the data or not"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:40:24.579459Z","iopub.status.busy":"2023-04-08T20:40:24.579037Z","iopub.status.idle":"2023-04-08T20:40:24.592222Z","shell.execute_reply":"2023-04-08T20:40:24.591004Z","shell.execute_reply.started":"2023-04-08T20:40:24.579420Z"},"id":"fa0s_Ish2Mjh","trusted":true},"outputs":[],"source":["def prepData(augment:bool):\n","    ''' Function to prepare the data using torch libraries for the purpose of training torch\n","        neural networks with relative ease.\n","        \n","        Using torch dataLoaders helps in memory management as well\n","        \n","        args : augment bool ---> True would enable data augmentation, False would disable.\n","        \n","        return : \n","            TrainDataLoader --> torch data loader wrapper for training dataset.\n","            ValDataLoader ----> torch data loader wrapper for validation data set.\n","            TestDataLoader ---> torch data loader wrapper for test data set.'''\n","    \n","    if augment == True:\n","        preProcess = transforms.Compose([\n","            transforms.Resize(size = (128,128)),\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.RandomVerticalFlip(p=0.2),\n","            transforms.ToTensor()\n","        ])\n","    else:\n","        preProcess = transforms.Compose([\n","            transforms.Resize(size = (128,128)),\n","            transforms.ToTensor()\n","        ])\n","    print(\"loading the data into tensors ==============================\")\n","    trainData = datasets.ImageFolder(root = \"/kaggle/working/inaturalist_12K/train\",\n","                                    transform = preProcess,\n","                                    target_transform = None)\n","    classLabels = trainData.classes\n","    \n","    testData  = datasets.ImageFolder(root = \"/kaggle/working/inaturalist_12K/val\",\n","                                    transform = preProcess)\n","\n","    print(f\"train data : {trainData} and test data : {testData}\")\n","\n","    print(\"splitting into train and val ================================\")\n","    trainSplit = ceil(0.8*len(trainData))\n","    trainData, valData = torch.utils.data.random_split(trainData, [trainSplit, len(trainData) - trainSplit])\n","\n","    print(\"wrapping into train loader ==================================\")\n","\n","    trainDataLoader = torch.utils.data.DataLoader(trainData,\n","                                                shuffle=True,\n","                                                batch_size=32)\n","\n","    valDataLoader = torch.utils.data.DataLoader(valData,\n","                                                shuffle=True,\n","                                                batch_size=32)\n","\n","    testDataLoader = torch.utils.data.DataLoader(testData,\n","                                                shuffle=False,\n","                                                batch_size=32)\n","    \n","    print(\"loaders created for faster loading ===========================\")\n","\n","\n","\n","    return trainDataLoader, valDataLoader, testDataLoader, classLabels"]},{"cell_type":"markdown","metadata":{},"source":["The class for the model made from scratch\n","- named CNN Model, inherits nn.Module.\n","- must have a forward function for completion and successful training.\n","- Flexibility with respect to layer size, kernel size, and batchNormalization(add/not add)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:40:28.566597Z","iopub.status.busy":"2023-04-08T20:40:28.566021Z","iopub.status.idle":"2023-04-08T20:40:28.589289Z","shell.execute_reply":"2023-04-08T20:40:28.585290Z","shell.execute_reply.started":"2023-04-08T20:40:28.566551Z"},"id":"3kyOIIShqGDP","trusted":true},"outputs":[],"source":["class CNNModel(nn.Module):\n","    ''' CNN Model for classifying the images\n","    \n","        __init__ : creates a blueprint for the model\n","        forward  : forward propagation facilitated by Torch Layers.'''\n","\n","    def __init__(self, activation, kernels, inputShape: int, hiddenUnit: int, outputSize: int, dropOut: float, batchNorm: bool, factor: int):\n","        \n","        ''' initialize the model == inherit from nn.Module\n","            \n","            args : activation --> activation Function torch.nn.$SomeValidActivationFunction$\n","                   kernels ---> list conatining 5 kernel sizes that may be taken as input.\n","                   inputShape --> Number of Channels in input data.\n","                   hiddenUnit --> Filter size.\n","                   outputSize --> number of output channels.\n","                   batchNorm ---> boolean var to indicate whether to add batch normalization or not.\n","                   factor ------> int value used as multiplier for subsequent layers.\n","        '''\n","        super().__init__()\n","        self.hiddenUnit = hiddenUnit\n","        self.factor = factor\n","        self.batchNorm = batchNorm\n","\n","        self.conv_blocks = nn.ModuleList()    # ModuleList (Torch container) used to record specific layers.  \n","        self.batch_norms = nn.ModuleList()    # Using ModuleList shortens boiler plate code.\n","\n","        layerSize = [inputShape] + [self.hiddenUnit] + [self.factor * self.hiddenUnit] * 4\n","        for i in range(5):\n","            self.conv_blocks.append(nn.Conv2d(layerSize[i], layerSize[i+1], kernel_size=kernels[i], padding=2))  # add conv layers\n","            if self.batchNorm:\n","                self.batch_norms.append(nn.BatchNorm2d(layerSize[i+1])) # add Batch normalization only if specified.\n","\n","        self.activate = activation  # add activation function (taken as input).\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # max pool layer (as and when to be used).\n","        self.drop = nn.Dropout(p=dropOut)  # drop out layer for reducing over fitting.\n","        \n","        # DenseBlock containing a flattening layer, dense layer.\n","        self.DenseBlock = nn.Sequential(\n","            nn.Flatten(),\n","            nn.LazyLinear(out_features=1024, bias=True, device=None, dtype=None), # LazyLinear used for calculation of in_features.\n","            nn.Dropout(p=dropOut),\n","            nn.Linear(in_features=1024, out_features=outputSize)\n","        )\n","\n","    def forward(self, x):\n","        ''' Forward Propagation\n","            x ---> tensor denoting input value.\n","            return x ---> prediction value.'''\n","        for i in range(5):\n","            x = self.conv_blocks[i](x)\n","            if self.batchNorm and i < 5:\n","                x = self.batch_norms[i](x)\n","            x = self.activate(x)\n","            x = self.pool(x)\n","\n","        x = self.drop(x)\n","        x = self.DenseBlock(x)\n","        x = nn.functional.softmax(x, dim=1)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:40:33.196617Z","iopub.status.busy":"2023-04-08T20:40:33.196109Z","iopub.status.idle":"2023-04-08T20:40:33.203877Z","shell.execute_reply":"2023-04-08T20:40:33.202748Z","shell.execute_reply.started":"2023-04-08T20:40:33.196572Z"},"trusted":true},"outputs":[],"source":["def accuracy(y_true, y_pred):\n","    ''' accuracy Function for calculating the percentage of y_true[i] == y_pred[i]\n","        args : y_true ---> int actual value/ label(s) of for the input(s).\n","        return : accuracy ---> float [0,100] The accuracy of the batch.\n","    '''\n","    correct = torch.eq(y_true,y_pred).sum().item()\n","    accuracy = 0.0\n","    accuracy = correct/(len(y_true))*100\n","    return accuracy"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:40:34.775166Z","iopub.status.busy":"2023-04-08T20:40:34.774593Z","iopub.status.idle":"2023-04-08T20:40:34.788512Z","shell.execute_reply":"2023-04-08T20:40:34.787450Z","shell.execute_reply.started":"2023-04-08T20:40:34.775128Z"},"id":"XyFNQ3Htw3RE","trusted":true},"outputs":[],"source":["def fit(model, trainDataLoader, valDataLoader, epochs, device, loss_fn, optimizer):\n","    ''' Function for training the model on the data set.\n","        args --->\n","            model -> CNNModule object \n","            trainDataLoader --> torch dataLoader wrapper containing training set.\n","            valDataLoader --> torch dataLoader wrapper containing validation set.\n","            epochs --> int, number of epochs.\n","            device --> whether cpu or cuda.\n","            loss_fn ---> loss Function used.\n","            optimizer --> optimizer function used.\n","            \n","        return model --> CNN Module object with updated weights.\n","    '''\n","    for epoch in tqdm(range(epochs)):\n","        train_loss = 0\n","        train_acc = 0\n","        for batch, (X,y) in enumerate(trainDataLoader):\n","            X,y = X.to(device), y.to(device)\n","            model.train()\n","            y_pred = model(X)\n","            loss = loss_fn(y_pred, y)\n","            train_loss += loss\n","            train_acc += accuracy(y_true=y, y_pred=y_pred.argmax(dim=1))\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch%50 == 0:\n","                print(f\"went through {batch}/{len(trainDataLoader)} samples\")\n","            torch.cuda.empty_cache()\n","\n","        train_loss /= len(trainDataLoader)\n","        train_acc /= len(trainDataLoader)\n","    \n","        val_loss = 0.0\n","        val_acc = 0\n","        model.eval()\n","        with torch.inference_mode():\n","            for X,y in valDataLoader:\n","                X,y = X.to(device), y.to(device)\n","                val_pred = model(X)\n","                val_loss += loss_fn(val_pred, y)\n","                val_acc += accuracy(y_true=y, y_pred=val_pred.argmax(dim=1))\n","            val_acc /= len(valDataLoader)\n","            val_loss /= len(valDataLoader)\n","        \n","        wandb.log({\"TrainingLoss\" : train_loss, \"ValidationLoss\" : val_loss, \"TrainingAccuracy\" : train_acc, \"ValidationAccuracy\" : val_acc, \"epoch\": epoch})\n","\n","        print(f\"Train loss: {train_loss}, Train accuracy: {train_acc}, validation loss: {val_loss}, validation accuracy: {val_acc}\\n\")\n","        \n","    return model\n","\n","    def eval(testDataLoader):\n","        ''' Function for evaluating the training on unseen test Dataset.\n","            args --> testDataLoader torch DataLoader object for easy loading/unloading.\n","        '''\n","        test_loss = 0.0\n","        test_acc = 0\n","        model.eval()\n","        with torch.inference_mode():\n","            for X,y in valDataLoader:\n","                X,y = X.to(device), y.to(device)\n","                test_pred = model(X)\n","                test_loss += loss_fn(val_pred, y)\n","                test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n","            test_acc /= len(testDataLoader)\n","            test_loss /= len(testDataLoader)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:40:37.005313Z","iopub.status.busy":"2023-04-08T20:40:37.004944Z","iopub.status.idle":"2023-04-08T20:40:37.018043Z","shell.execute_reply":"2023-04-08T20:40:37.016964Z","shell.execute_reply.started":"2023-04-08T20:40:37.005280Z"},"id":"M7C2ThVtB0Kx","trusted":true},"outputs":[],"source":["def masterTrainer(trainDataLoader, valDataLoader, testDataLoader, learningRate, kernels, layerSize, dropOut, batchNorm, activation, factor, epochs):\n","    ''' function to start the training and facilitate wandb logging.\n","        args ->\n","            trainDataLoader --> torch dataLoader wrapper containing training set.\n","            valDataLoader --> torch dataLoader wrapper containing validation set.\n","            testDataLoader --> torch dataLoader wrapper containing test dataset.\n","            \n","            learningRate ---> int, learning rate,\n","            kernels --> list of kernel sizes, one for each convolutional layer.\n","            layerSize --> filter size of first convolutional layer\n","            factor --> multiplier to number of filters for subsequent training.\n","            epochs --> int, number of epochs.\n","    '''\n","    activations = {\n","    \"relu\" : torch.nn.ReLU(),\n","    \"gelu\" : torch.nn.GELU(),\n","    \"silu\" : torch.nn.SiLU(),\n","    \"mish\" : torch.nn.Mish()\n","    }\n","\n","    #import wandb    \n","    #wandb.init(project=\"DLAssignment2\", entity=\"cs22m028\")\n","    #wandb.run.name = \"config_\"+str(optimizer)+\"_\"+str(layerSize)+\"_\"+str(decay)+\"_\"+str(opt)+\"_\"+str(batchNorm)+\"_\"+str(dropOut)+\"_\"+str(activation)    \n","    activate= activations[activation]\n","\n","    model_0 = CNNModel(activate, kernels, inputShape=3, hiddenUnit=layerSize,outputSize=10, dropOut = dropOut, batchNorm=True, factor = 2)\n","\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    model_0.to(device)\n","    #from helper_functions import accuracy_fn as accuracy # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(params = model_0.parameters(),lr=learningRate)\n","    print(model_0)\n","    fit(model_0, trainDataLoader, valDataLoader, epochs, device, loss_fn, optimizer)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:40:46.360549Z","iopub.status.busy":"2023-04-08T20:40:46.360145Z","iopub.status.idle":"2023-04-08T20:40:46.368860Z","shell.execute_reply":"2023-04-08T20:40:46.367715Z","shell.execute_reply.started":"2023-04-08T20:40:46.360515Z"},"id":"ssI1H_s7sK_m","trusted":true},"outputs":[],"source":["def wandbTrainer():\n","    ''' wandb trainer for initializing runs, loading data and running the entire training/ testing process.'''\n","    wandb.init(project=\"DLAssignment2\", entity=\"cs22m028\")\n","    wandb.run.name=\"config_activation=\"+str(wandb.config.activation)+\"_epochs=\"+str(wandb.config.epochs)+\"_dropOut=\"+str(wandb.config.dropOut)+\"_batchSize=\"+str(wandb.config.batchSize) + \"_filterSize=\"+str(wandb.config.filterSize)+\"_batchNorm=\"+str(wandb.config.batchNorm)+\"_augment=\"+str(wandb.config.augmentation)+\"_learningRate=\"+str(wandb.config.learningRate)\n","    trainDataLoader, valDataLoader, testDataLoader, classLabels = prepData(augment=wandb.config.augmentation)\n","    #trainDataLoader, valDataLoader, testDataLoader, classLabels = prepData(augment=True)\n","    #masterTrainer(trainDataLoader, valDataLoader, testDataLoader, 0.001, 0.00001, [5,5,3,3,3], 32, \"adam\", \"cross\", 0.2, True, \"gelu\", 1)\n","    masterTrainer(trainDataLoader, valDataLoader, testDataLoader, wandb.config.learningRate, wandb.config.kernels, wandb.config.filterSize, wandb.config.dropOut, wandb.config.batchNorm, wandb.config.activation, wandb.config.factor, wandb.config.epochs)\n","    #masterTrainer(trainDataLoader, valDataLoader, testDataLoader, config.wandb.learningRate, config.wandb.decay, config.wandb.kernels, config.wandb.layerSize, config.wandb.dropOut, config.wandb.batchNorm, config.wandb.activation, config.wandb.factor)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T20:40:51.345118Z","iopub.status.busy":"2023-04-08T20:40:51.344757Z","iopub.status.idle":"2023-04-08T21:10:13.386778Z","shell.execute_reply":"2023-04-08T21:10:13.385528Z","shell.execute_reply.started":"2023-04-08T20:40:51.345086Z"},"id":"t_4U_ofB7FJo","outputId":"5bd66bc5-ab40-452f-a5ef-942353375694","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["Create sweep with ID: o4emrjts\n","Sweep URL: https://wandb.ai/cs22m028/DLAssignment2/sweeps/o4emrjts\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f20hioh2 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n","\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: True\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchNorm: True\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropOut: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfactor: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfilterSize: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tkernels: [3, 3, 3, 3, 3]\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m028\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"]},{"data":{"text/html":["wandb version 0.14.2 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.14.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20230408_204058-f20hioh2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/cs22m028/DLAssignment2/runs/f20hioh2' target=\"_blank\">youthful-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m028/DLAssignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m028/DLAssignment2/sweeps/o4emrjts' target=\"_blank\">https://wandb.ai/cs22m028/DLAssignment2/sweeps/o4emrjts</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/cs22m028/DLAssignment2' target=\"_blank\">https://wandb.ai/cs22m028/DLAssignment2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/cs22m028/DLAssignment2/sweeps/o4emrjts' target=\"_blank\">https://wandb.ai/cs22m028/DLAssignment2/sweeps/o4emrjts</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/cs22m028/DLAssignment2/runs/f20hioh2' target=\"_blank\">https://wandb.ai/cs22m028/DLAssignment2/runs/f20hioh2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["loading the data into tensors ==============================\n","train data : Dataset ImageFolder\n","    Number of datapoints: 9999\n","    Root location: /kaggle/working/inaturalist_12K/train\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=None)\n","               RandomHorizontalFlip(p=0.5)\n","               RandomVerticalFlip(p=0.2)\n","               ToTensor()\n","           ) and test data : Dataset ImageFolder\n","    Number of datapoints: 2000\n","    Root location: /kaggle/working/inaturalist_12K/val\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=None)\n","               RandomHorizontalFlip(p=0.5)\n","               RandomVerticalFlip(p=0.2)\n","               ToTensor()\n","           )\n","splitting into train and val ================================\n","wrapping into train loader ==================================\n","loaders created for faster loading ===========================\n","CNNModel(\n","  (conv_blocks): ModuleList(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","  )\n","  (batch_norms): ModuleList(\n","    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (activate): Mish()\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (drop): Dropout(p=0.3, inplace=False)\n","  (DenseBlock): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): LazyLinear(in_features=0, out_features=1024, bias=True)\n","    (2): Dropout(p=0.3, inplace=False)\n","    (3): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73aad317e8ad42f6bbbadb3e47852ccb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.2351627349853516, Train accuracy: 20.8875, validation loss: 2.1905922889709473, validation accuracy: 25.076058201058203\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.1775753498077393, Train accuracy: 27.2125, validation loss: 2.1598708629608154, validation accuracy: 29.937169312169313\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.163022994995117, Train accuracy: 28.95, validation loss: 2.1705877780914307, validation accuracy: 28.04563492063492\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","Train loss: 2.147533416748047, Train accuracy: 30.7, validation loss: 2.145045280456543, validation accuracy: 31.091269841269842\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.1408932209014893, Train accuracy: 31.3625, validation loss: 2.137394905090332, validation accuracy: 31.91468253968254\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.1294431686401367, Train accuracy: 32.525, validation loss: 2.1331546306610107, validation accuracy: 31.765873015873016\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.123131513595581, Train accuracy: 32.7875, validation loss: 2.124224901199341, validation accuracy: 32.820767195767196\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.122258424758911, Train accuracy: 33.2, validation loss: 2.1333045959472656, validation accuracy: 31.828703703703702\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.1206061840057373, Train accuracy: 33.1875, validation loss: 2.1306138038635254, validation accuracy: 32.57936507936508\n","\n","went through 0/250 samples\n","went through 50/250 samples\n","went through 100/250 samples\n","went through 150/250 samples\n","went through 200/250 samples\n","Train loss: 2.108717441558838, Train accuracy: 34.7875, validation loss: 2.117910385131836, validation accuracy: 33.60780423280423\n","\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fb1a5e31e224ab19ecfb397d2a58d1b","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>TrainingAccuracy</td><td>▁▄▅▆▆▇▇▇▇█</td></tr><tr><td>TrainingLoss</td><td>█▅▄▃▃▂▂▂▂▁</td></tr><tr><td>ValidationAccuracy</td><td>▁▅▃▆▇▆▇▇▇█</td></tr><tr><td>ValidationLoss</td><td>█▅▆▄▃▂▂▂▂▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>TrainingAccuracy</td><td>34.7875</td></tr><tr><td>TrainingLoss</td><td>2.10872</td></tr><tr><td>ValidationAccuracy</td><td>33.6078</td></tr><tr><td>ValidationLoss</td><td>2.11791</td></tr><tr><td>epoch</td><td>9</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">youthful-sweep-1</strong> at: <a href='https://wandb.ai/cs22m028/DLAssignment2/runs/f20hioh2' target=\"_blank\">https://wandb.ai/cs22m028/DLAssignment2/runs/f20hioh2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230408_204058-f20hioh2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"]}],"source":["if __name__ == '__main__':\n","    wandb.login(key='1f3d400868fd8a06335a2177ed2ee9def37df31d')\n","    sweep_config = {\n","        'method': 'bayes'\n","        }\n","\n","    metric = {\n","        'name': 'val_acc',\n","        'goal': 'maximize'   \n","        }\n","\n","    sweep_config['metric'] = metric\n","\n","    parameters_dict = {\n","        'epochs' : {\n","            'values':[10,15,20]\n","        },\n","        'factor':{\n","            'values':[2, 1, 0.5]},\n","        'filterSize': {\n","            'values': [32, 64, 128]\n","            },\n","        'dropOut' : {\n","            'values' : [0.2, 0.3, 0.42, 0.5]\n","            },\n","        'batchSize' : {\n","            'values' : [16, 32, 64]\n","            },\n","        'activation' : {\n","            'values' : ['mish', 'gelu', 'relu', 'silu']\n","            },\n","        'augmentation' : {\n","            'values':[True, False]\n","        },\n","        'batchNorm' : {\n","            'values' : [True, False]\n","            },\n","        'kernels' : {\n","            'values' : [[3, 3, 3, 3, 3,], [5, 5, 3, 3, 3], [7, 5, 3, 3, 3]]\n","            },\n","        'learningRate' : {\n","            'values' : [0.001, 0.0005, 0.00075, 0.0001, 0.0002]\n","         }\n","        }\n","\n","    sweep_config['parameters'] = parameters_dict\n","\n","    sweep_id = wandb.sweep(sweep_config, project= \"DLAssignment2\")\n","    wandb.agent(sweep_id,project= \"DLAssignment2\" , function = wandbTrainer)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
